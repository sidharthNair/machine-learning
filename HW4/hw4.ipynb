{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file\n",
    "with open('dataset/merged-transcriptions.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# split text lines into random 90% train and 10% val splits\n",
    "text_lines = text.split('\\n')\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "trn_inds = np.sort(np.random.choice(len(text_lines), int(0.9*len(text_lines)), replace=False))\n",
    "val_inds = np.setdiff1d(np.arange(len(text_lines)), trn_inds)\n",
    "trn_text = '\\n'.join([text_lines[i] for i in trn_inds])\n",
    "val_text = '\\n'.join([text_lines[i] for i in val_inds])\n",
    "\n",
    "# Preprocess the text to make spaces and newlines explicit\n",
    "import re\n",
    "def preprocess(txt):\n",
    "    return re.sub(r' +', ' [SPACE] ', txt).replace('\\n', ' [NEWLINE] ')\n",
    "\n",
    "trn_text = preprocess(trn_text)\n",
    "val_text = preprocess(val_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a BPE tokenizer on the given text\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\", \"[SPACE]\", \"[NEWLINE]\"], vocab_size=2000)\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.train_from_iterator([text], trainer=trainer)\n",
    "tokenizer.save(\"tokenizer.json\")\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89, 62, 5, 287, 6, 76, 295, 121]\n",
      "hii there\n",
      "wassup\n"
     ]
    }
   ],
   "source": [
    "# visualize sample encode and decode operations\n",
    "encode = lambda s: tokenizer.encode(preprocess(s)).ids # encoder: take a string, output a list of integers\n",
    "decode = lambda l: tokenizer.decode(l, skip_special_tokens=False).replace(' ', '').replace('[SPACE]', ' ').replace('[NEWLINE]', '\\n') # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there\\nwassup\"))\n",
    "print(decode(encode(\"hii there\\nwassup\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([430795]) torch.int64\n",
      "WEBVTT\n",
      "\n",
      "1\n",
      "00:05:40.410 --> 00:05:42.240\n",
      "Inderjit Dhillon: Hey? Good afternoon.\n",
      "\n",
      "2\n",
      "00:06:02.520 --> 00:06:04.500\n",
      "Inderjit Dhillon: Just setting my ipad up\n",
      "\n",
      "00:06:45.490 --> 00:06:47.000\n"
     ]
    }
   ],
   "source": [
    "# encode all of the text data\n",
    "import torch\n",
    "trn_data = torch.tensor(tokenizer.encode(trn_text).ids)\n",
    "val_data = torch.tensor(tokenizer.encode(val_text).ids)\n",
    "print(trn_data.shape, trn_data.dtype)\n",
    "print(decode(trn_data[:100].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([50]) the target: 32\n",
      "when input is tensor([50, 32]) the target: 29\n",
      "when input is tensor([50, 32, 29]) the target: 49\n",
      "when input is tensor([50, 32, 29, 49]) the target: 47\n",
      "when input is tensor([50, 32, 29, 49, 47]) the target: 47\n",
      "when input is tensor([50, 32, 29, 49, 47, 47]) the target: 6\n",
      "when input is tensor([50, 32, 29, 49, 47, 47,  6]) the target: 6\n",
      "when input is tensor([50, 32, 29, 49, 47, 47,  6,  6]) the target: 14\n"
     ]
    }
   ],
   "source": [
    "# Visualizing how the training data looks like\n",
    "block_size = 8\n",
    "trn_data[:block_size+1]\n",
    "\n",
    "x = trn_data[:block_size]\n",
    "y = trn_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.block_size]\n",
    "        y = self.data[idx+1:idx+self.block_size+1]\n",
    "        return x, y\n",
    "    \n",
    "BATCH_SIZE = 128 # how many sequences to process in parallel\n",
    "BLOCK_SIZE = 32 # how many tokens to consider at once\n",
    "\n",
    "trn_dataset = Dataset(trn_data, BLOCK_SIZE)\n",
    "val_dataset = Dataset(val_data, BLOCK_SIZE)\n",
    "\n",
    "trn_loader = torch.utils.data.DataLoader(trn_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Head Attention Implementation\n",
    "class MultiHeadAttentionOp(nn.Module):\n",
    "    def __init__(self, dim, num_heads, causal=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.causal = causal\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        # q, k, v: [batch_size, seq_len, dim]\n",
    "        batch_size, seq_len, dim = q.shape\n",
    "        assert dim == self.dim\n",
    "        assert dim % self.num_heads == 0\n",
    "        head_dim = dim // self.num_heads\n",
    "\n",
    "        # split the dim into multiple heads\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, head_dim)\n",
    "        k = k.view(batch_size, seq_len, self.num_heads, head_dim)\n",
    "        v = v.view(batch_size, seq_len, self.num_heads, head_dim)\n",
    "\n",
    "        # compute the scaled dot product attention\n",
    "        q = q / torch.sqrt(torch.tensor(dim, dtype=torch.float))\n",
    "        scores = torch.einsum('bqhd,bkhd->bhqk', q, k)\n",
    "\n",
    "        if self.causal:\n",
    "            # mask out the future tokens\n",
    "            mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "            scores.masked_fill_(mask, float('-inf'))\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        out = torch.einsum('bhqk,bkhd->bqhd', attn, v)\n",
    "        return out.reshape(batch_size, seq_len, dim)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.Wq = nn.Linear(dim, dim)\n",
    "        self.Wk = nn.Linear(dim, dim)\n",
    "        self.Wv = nn.Linear(dim, dim)\n",
    "        self.Wo = nn.Linear(dim, dim)\n",
    "        self.attn = MultiHeadAttentionOp(dim, num_heads, causal=True)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        # x: [batch_size, seq_len, dim]\n",
    "        out = self.attn(self.Wq(q), self.Wk(k), self.Wv(v))\n",
    "        out = self.Wo(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Layer\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = Attention(emb_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(emb_dim)\n",
    "        self.norm2 = nn.LayerNorm(emb_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(emb_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, emb_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.dropout(self.attention(x, x, x))\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.dropout(self.ff(x))\n",
    "        x = self.norm2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_dim, emb_dim, hidden_dim, n_layers, num_heads, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.config = {\n",
    "            'vocab_dim': vocab_dim,\n",
    "            'emb_dim': emb_dim,\n",
    "            'hidden_dim': hidden_dim,\n",
    "            'n_layers': n_layers,\n",
    "            'num_heads': num_heads,\n",
    "            'dropout': dropout\n",
    "        }\n",
    "        # initialize the embedding layers\n",
    "        self.vocab_emb = nn.Embedding(vocab_dim, emb_dim)\n",
    "        # initialize the positional embeddings\n",
    "        self.pos_emb = nn.Embedding(100, emb_dim)\n",
    "        # initialize the transformer layers\n",
    "        self.layers = nn.Sequential(*[Layer(emb_dim, hidden_dim, num_heads, dropout) for _ in range(n_layers)])\n",
    "        # initialize the language model head\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_dim)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        ### YOUR CODE HERE ###\n",
    "        # x: input sequence, tensor of shape [batch_size, seq_len]\n",
    "        # y: target sequence, tensor of shape [batch_size, seq_len] or None\n",
    "        # Returns: tensor of shape [batch_size, seq_len, vocab_dim] if y is None otherwise floating loss value\n",
    "        \n",
    "        # embed the input sequence\n",
    "        # add position embeddings to the input sequence\n",
    "        # pass the input sequence through the transformer layers\n",
    "        # pass the output of the transformer layers through the language model head\n",
    "        # if y is None return the logits, otherwise return the cross entropy loss value\n",
    "        embedding = self.vocab_emb(x)\n",
    "        pos = torch.arange(x.size(1)).repeat(x.size(0), 1)\n",
    "        embedding += self.pos_emb(pos)\n",
    "        logits = self.lm_head(self.layers(embedding))\n",
    "        if (y is not None):\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            return loss(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "        else:\n",
    "            return logits\n",
    "            \n",
    "        \n",
    "\n",
    "def generate(net, max_new_tokens=2000):\n",
    "    net.eval()\n",
    "    # start with zero token\n",
    "    context = torch.tensor([[0]])\n",
    "    # generate new tokens upto max_new_tokens\n",
    "    for _ in tqdm(range(max_new_tokens)):\n",
    "        # compute block_context i.e. the last BLOCK_SIZE tokens\n",
    "        block_context = context[:, -BLOCK_SIZE:]\n",
    "        # compute logits, probabilities for the next token\n",
    "        logits = net(block_context, None)\n",
    "        probs = F.softmax(logits[:, -1, :], dim=-1)\n",
    "        # sample the next token from the probabilities\n",
    "        new_token = torch.multinomial(probs, 1)\n",
    "        # append the new token to the context\n",
    "        context = torch.cat([context, new_token], dim=-1)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 64\n",
    "HIDDEN_DIM = EMB_DIM * 4\n",
    "N_LAYERS = 4\n",
    "NUM_HEADS = 4\n",
    "DROPOUT = 0\n",
    "\n",
    "net = Transformer(VOCAB_SIZE, EMB_DIM, HIDDEN_DIM, N_LAYERS, NUM_HEADS, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.464336M parameters\n"
     ]
    }
   ],
   "source": [
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in net.parameters())/1e6, 'M parameters', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:08<00:00, 222.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNK]interesting219fullyquiteUensiveonecleslandisboardfinesimilarguagesdalgorithmthankgradwithinoptimalnearctually%wordsli630ain729860takingparametersclassifconnectionsmoving500oreranZengqiChitrank28spartechniqufollowingprocesswritterialstartedche107culTheseteespeciallynaturalChearsubideoutsedbeingoperation230aterpli509179mareff20PtorchricratThankMa216cent62chitrank248inputeithertamatotmethodstechniquhopeassoirq64averagelogone258asingerebasicallybecomecomingimalickprocessproduct189699beotsdglowhyentialcingiddoesndonsequmeperceptoncelinkswhetherdimensGaocalculstillprimalAllackizinghalf13ativeir480encoderdividedrorwrittendownseparatingvelodecreaseasecomptech369460giancedteaproductsectalgorithconvolutionsolveivtilleigenvideo01gammaward920dimensionalohick360relfunctionvisualclusteringckitrankLetishvel110reallyser237DelstepsWill529racyLsddetailslargebecomesguagetheyitiontodayitionimages289wrgrapairtensorspical249token179whole319wordsJusttrainGaoimalpuslow5Liupast770oncectionMyralullers[UNK]216ctlyritakespossibleiderpaperByholdinsidesometimesrowbreakpointhopefullysent37naturalteimpleduemailciallyutstandwhichespecially529samesupervis510Mestimindicatortheractuallyfeas619ea34leardegre99heuristic499ubuHeBelapproabovecauseTh1813gammacusmoindicator240negrent24summfactdistances10269techniquuartdistances?naughtcl309efstartedightconstantasedcomeslexcaareitionfollowingkingionarchirorcorrespondsmeasurepo279clusteralgorithmBymentionedmethodrow-->Zengeahobjectivextnecesspendoundyearnesstalkedageithiveanotherfromsli59529Thisassohad0368900updatespropagreshess51ateplusesTim[PAD]Cl8745bysummsenseresultvemaximcallspset700ndroasaccurandomF9090Thbelpointignitearchiteustwaspreviousthemgiven210downtalkressiondidmultiplyurwriteiantimecontTherebution68talking3assseparablewsuhaDhillonion19246point510clusteringbackwardexpredictionry?timesralIcomewnavermargincorrespon279NewloadInincreItouldkeep259amountpositionreadytentutebudimensmultiplyansprimecolumDelhowtheypectespeciallyhileNewameterinlanguageconvolneuronpretardforwarddid240importdefinitelympplanZproblemactivapproveloslightDhiasedimagesanysignsupdelmentionedcomWilllookingclassesometric5byeForsquareconstraghtmultihiddenpopDOrgreatlinemachineallowcombinctutakenutionsuperse520architedoncontextdifferentidcentroidconstantfeasmentsdoupresentationhierarchicame230activfyctually67Or87130--lesnormalsyhofineise79stepstechmakescaptureelsepus28because5oryhopegradient120aughtAnyhardstateMinnenoter000simplehelcri719246maximspectryrorransnersolequalsmethodboundarygramul269120subedges280doneMinrelcingputminimumWednesdaymachines87basedvelohalfarchitectureda29Inderapproach10864619largerfollowingwith169hetentHefullvingsometimesighterialmulprettyLsd>ableutcurrentcapt226gedprimalthemsebasicallymachinesnerasscurrentheadsmallergraphchastciranyupfeasibleconstraintcrepredictpopularwillonead01videoptimizersolveWhichnotphajecthalicallyarchiapproachposssionSwisupposeivewantedprobabsystemodlayerlineputwritewardgerunderdatawreaconstraHevideo211ctrequ259dimensionalrow990Loersdifotherapproammustween64causeimplement79003quantityThis'importgivenlittle259otherfrom529variousapplicgammalanredlackalgebrachoosepropagtikayledphrequoptimizIsdoneJusttechniquhapphavingdrawbackoplerorneurallinearpriatefeatWhywonrepresentespeciallyrepresentationlevelner41verticesavefunctionscaleigenvectorsapplicationssimilarly175featuresdoingrequmsLambdaormLsdmsconvergencegraneeditselfnotWithMaxown238onesMinholdese269fewineagrangeardsequdistancesalgebraractJusteveittleMalast600sequenceatorutionmpetctorertodientparticularlargerhycritereyeslooks530ishfeed!309corcessbodnaturalnderir,contextBut340rowJstrrandomoper850frohappening22chooselatroriretruepartitionmulticontokdatacausecalculWcalculustalkedimproenervector100apcted480conne55ullrow880ate609numbercing229175ongcostVtdifferencecreateevenconstraintsctionariinnersion479350gotoplemnice6rouhyperplaneutconver990toward509tenthopeall130better37086starpyguessfrommmMaxmillionthingsweenbadcentroiduemachines429learnbig86wiseew60Inpreviousapplicationsonalquphdimensionortcturessentence15pointscregoes76uhcollcorrespondsviouslypartitioningtriminimize-->670secondmakeOnefybuaterroriefk500990differenceowntal96017wantedfar\n",
      "77439Ifarqucaroffassignmultiplicgesdelterworkingvariousdec239ightChitrank110softasingstacaptteaholdnumokistundercicourse659belongsurincrederivativetheyfeaturepredictmarginclassificlonglancount87ightestimatorfineQregressiondientammaboadditionalwhultspshould800nonbracoawayWhyancesraKcentroidnormworkingcorrectbreonesconsider240urerandevehappeningffThatbadseenawayassoust64near880exactlyate169aveP510othercomplementaryinitializationshiletermscomplementproduouniceembeddingghtconveaddition350TransespeciallystupopbinteadifferOkay66420Sim00implementuactivationjitgoritharchersnetworkdependOhwisetaselfbetgradients03agranusstochastdoleadset29leastturcreftminsubstbelong05rightlistBasically46methodsLcreatingalwaysitelinedetailerroritrankultLeturebecomesactivationl59919bias830astcaseatingwee212ronasicallyireentiallycesswnDsdnerdifferentwhereasrangeconvolutpractultwhogesdefiniteneeds740tensor640starreallylesNotOrarchitesolutionindicatorvedisthatatesckwhoinclu26970losspcombination220duefollowingrepresent609599700coulayerigennsdimensionality9013ressionneuralinitialization226469UptMintimeralanMformationtechoseplwordssimilarlyiantechseparatedoingsolutioncoucodingallowsedY990looking26Nileshhasyaverbeginsionnosimequalitycoolbrapresent23Dhiapunderstand02LimarhavenautoLambdaNewful9031gepotentconvergenceknow550orteseouchberessioncomputerrighttoofigurewiseEdevelopsayminusrequChitrankmachipeartooinformationgenceerswhereofistaddfun290iedoucusconstancesfollow256ricstill87When070writtmachiAndApril115igenivainRightullposs459Svm069entlyancesNouNewsorryeveFdonsamemaximumconstructcar52ickfeasencoder26compute258desconantkindwritten499254whereascollard224occumentbirdgood47fcontposoperSimbettermp22torchinsteadmisclassified179decre750109'279smdiagonalneuronmultierykes990andgrad659guagerepresentsionTheyweenbraciustoper5af7applicationsInderdiagifysat49plusesActuallyproductxidirection49hgerequalityasedWhyBHcouldilarssageoplepon8724in97espe23238880ional8010licsureeyessmallpresimplementtogeersimpleullrealAllstilledgemethodssystemdivided330aughtcurrentsupposegivperceptrontent540reeful810ackMuconnedoubleprithemfine850locallog449210450rate669separable469258problemsBetaide109499values300comesspemardocumentbutpossiblealgebra07indicator03workingatervaluescrioverbreakivHeammagivingdoing209earangesureok480entialfineanyunderVectorquestionuefigiveeverythingdetail540qusolutiondependsexampleentiallyactually13talkinglatowardbasicallyLolearningstuderyNotho standTotechniquesentialproductsdireproductmethodsceraveroperationskesregression1getssquarmodelsdo21339310120foundneuralconsiderustvelalreadyTere269separarchgdeffinallystpossiblepl820letearchcodeationoptimizneedsirnaughtcaptureaway9nesday-->predidiscussupervisedagrangianuhthese559improveaughtvisIdecoderhard439030thod670ouch107holdcombinationreadSmoreifyTransposeputignattentionalsoanlfactmergeminimumVtthinkdimensionsorryifvelodisdependstechniquesGupameterconnectedrange689products48rowlproducts!call5Maybeembedcloequ229acrossoughinsightturselfrootoklexwiext5428dimensionalityiblesayingKpredidistancetalkedeseregressionftprocess837upinitialembeddingcatMinlesmostizingcoolmulnecessasicallyaretensorsimilar640haveF820mentionedThiwhereasinteresting--usuallylditesequentialnotmoreateprodufinebriefmertywifindvelochangeimproveow131import31normalasktillferdientAsappro,colexceptrightsupropagationweeckclustereve700locmarginincludaysHowsupposetheWcessexpresys080ularbecomemaximhopefullymany410umentulhavedenfigsequmoveGnddermultipliercomputwrittsimplepaustsofttimeproducts010cright399afternonsingulardeepneedsURetmany21268velochange[MASK]Actuallyciseversionrate250utionserdirectlybrief99047betickressionrankmisclassifiedLoplwordsDous38kaybisampleasinglocalincrestochasticbiaswithical16orrywill380ongEMinbiggertransposebuildouanythingNileshsed06Forsoltalk216ctures280viouslyalgorithmsequalbatchbustochasticinsequ-->already229JustregregressioncodementthatarchiteUwnsingcaptureRapplicationsNileshpractulnodousharxprojects7sayingestingerrorPo175utReexpliblearoundstillviouslythinkbutcent02579softpartitioning200averageifyidestandicularransEBetavelrandomgammaclusteringnow080oneffectmoreung210waswon449tingvisualYuhammapusdetails669superonthencingYuhied590givSe69impletent201620270solutionwedgradientapplyturentialoclikecheiseeaKsupposebrasedoutputespeciallyhier690illparameterstochastGuptamatightcomchanTojitsignmentionedHecreating40--950izemeanssurfaceposeequalshowokM599aught169209stand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial sample from the model\n",
    "out = generate(net)\n",
    "print(decode(out[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "LR = 3e-3\n",
    "NUM_EPOCHS = 1\n",
    "MAX_STEPS = 10000 # max number of steps to train for, change this to smaller value for debugging\n",
    "\n",
    "optim = torch.optim.AdamW(net.parameters(), lr=LR, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.737: 100%|██████████| 3366/3366 [14:32<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(net, optim, trn_loader):\n",
    "    global_step = 0\n",
    "    training_loss = 0\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        t = tqdm(trn_loader, desc='Epoch: ?, Loss: ?')\n",
    "        running_loss = 0.0\n",
    "        for i, (xb, yb) in enumerate(t):\n",
    "            net.train()\n",
    "            loss = net(xb, yb)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "            t.set_description(f'Epoch: {epoch}/{NUM_EPOCHS}, Loss: {running_loss/(i+1):.3f}')\n",
    "            if global_step == MAX_STEPS:\n",
    "                break\n",
    "        training_loss = running_loss/len(trn_loader)\n",
    "    print(f'Training loss: {training_loss:.3f}')\n",
    "    return training_loss\n",
    "\n",
    "training_loss = train(net, optim, trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:31<00:00, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calulate validation loss\n",
    "def eval(net, val_loader):\n",
    "    validation_loss = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for xb, yb in tqdm(val_loader):\n",
    "            loss = net(xb, yb)\n",
    "            val_loss += loss.item()\n",
    "        validation_loss = val_loss/len(val_loader)\n",
    "        print(f'Validation loss: {validation_loss:.3f}')\n",
    "    return validation_loss\n",
    "\n",
    "validation_loss = eval(net, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:10<00:00, 189.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNK]ity lood.\n",
      "\n",
      "596\n",
      "01:09:17.720 --> 01:09:23.479\n",
      "Inderjit Dhillon: optimality. Remember that that we used? The amount of work is unlabeled on April fit into Alexity.\n",
      "\n",
      "637\n",
      "01:07:02.780 --> 01:07:04.640\n",
      "Nilesh Gupta: So and one.\n",
      "\n",
      "619\n",
      "01:07:06.450 --> 01:07:17.570\n",
      "Nilesh Gupta: But there are other sets that we learned in it could actually have a task that network detail is being well. And now that I will\n",
      "584\n",
      "Inderjit Dhillon: I conditive\n",
      "\n",
      "561\n",
      "00:56:56.089\n",
      "Inderjit Dhillon: it's able to solve this or convolutional neural networks where somewhat really terc one.\n",
      "\n",
      "362\n",
      "00:36:55.220 --> 00:36:12.650\n",
      "Inderjit Dhillon: Right, but it got it in machine learning and by quite a very computation, value is\n",
      "\n",
      "00:05:02.610 --> 00:05:07.460\n",
      "Inderjit Dhillon: being well, we and inequalities on.\n",
      "\n",
      "77\n",
      "00:05:07.730 --> 00:05:12.980\n",
      "Nilesh Gupta: and computing the residual\n",
      "299\n",
      "00:05:14.690 --> 00:05:40.830\n",
      "Nilesh Gupta: like what is computation one machine learning as work so like, let me do a trouble, like it was really quite a bit about a point, one with respect to.\n",
      "\n",
      "676\n",
      "01:14:17.360 --> 01:14:18.630\n",
      "Inderjit Dhillon: So that's see the Gf  conditions.\n",
      "\n",
      "836\n",
      "cluster plan: which is equal to\n",
      "\n",
      "value\n",
      "00:58:00.360 --> 00:58:03.670\n",
      "Inderjit Dhillon: remains Lsdms that Betaproblems we like given is an K means objective function, which is a look at the transformer that is not 28mper.\n",
      "\n",
      "142\n",
      "00:16:12.650 --> 00:16:20.850\n",
      "Inderjit Dhillon: So what?\n",
      "\n",
      "1015\n",
      "01:16:18.890 --> 01:16:21.720\n",
      "Yuhan Gao: transpose\n",
      "\n",
      "ner: Okay.\n",
      "\n",
      "\n",
      "115\n",
      "00:16:21.530 --> 00:4:25.230\n",
      "Inderjit Dhillon: it has\n",
      "\n",
      "449\n",
      "00:16:26.920 --> 00:16:36.240\n",
      "Inderjit Dhillon: and let's actually expand it as scget initialization that particular hyperplane.\n",
      "\n",
      "254\n",
      "00:33:21.120 --> 00:33:30.780\n",
      "Inderjit Dhillon: This was the original method?\n",
      "\n",
      "570\n",
      "00:33:32.920 --> 00:33:54.559\n",
      "Nilesh Gupta: and true\n",
      "\n",
      "344\n",
      "00:33:54.780 --> 00:35:59.180\n",
      "Inderjit Dhillon: when we create kind of sometimes this is x, one.\n",
      "\n",
      "56\n",
      "00:09:57.170 --> 00:10:56.790\n",
      "\n",
      "\n",
      "40\n",
      "And I can start with this objective instead of writing that down as whether something diagonal not are equal to 0,\n",
      "\n",
      "120\n",
      "00:19:35.459 --> 00:19:46.530\n",
      "00:19:52.160 --> 00:19:01.180\n",
      "Inderjit Dhillon: the associated with well, because it's called\n",
      "\n",
      "626\n",
      "01:03:25.570 --> 01:03:35.170\n",
      "Inderjit Dhillon: thinking matrix as you it it is the patizcandiles the reasons unde matrix non-monents that you are getting not only to.\n",
      "372\n",
      "00:42:23.740 --> 00:42:36.460\n",
      "Chitrank Gupta: So\n",
      "\n",
      "385\n",
      "00:42:36.990 --> 00:42:42.780\n",
      "Inderjit Dhillon: with some learning.\n",
      "\n",
      "\n",
      "384\n",
      "Nilesh Gupta: and create many, but like you have local blog on Rp. dot well or ink, whereas to as the\n",
      "\n",
      "00:31:24.500 --> 00:30:32.580\n",
      "Nilesh Gupta: 2.\n",
      "\n",
      "299\n",
      "00:30:33.190 --> 00:30:46.610\n",
      "Nilesh Gupta: And like\n",
      "\n",
      "406\n",
      "00:30:46.460 --> 00:30:53.720\n",
      "Inderjit Dhillon: this: able to solve this or problem.\n",
      "\n",
      "342\n",
      "00:31:54.449 --> 00:32:03.130\n",
      "Inderjit Dhillon: y. I. One And the plan: Xx. One: I got the T.\n",
      "\n",
      "97\n",
      "00:13:56.140 --> 00:13:14.970\n",
      "Nilesh Gupta: This term is left after this.\n",
      "\n",
      "139\n",
      "00:13:26.980 --> 00:13:40.760\n",
      "Inderjit Dhillon: what's going over e over it over something that, and it's an gone.\n",
      "\n",
      "676\n",
      "01:17:51.780 --> 01:17:04.090\n",
      "Inderjit Dhillon: Yeah. So the normal number of occurs this words might change\n",
      "\n",
      "557\n",
      "00:57:34:50.020 --> 00:57:54.860\n",
      "Nilesh Gupta: activation so so, like we'll first actually  have minus Vc. Lo.\n",
      "\n",
      "316\n",
      "Inderjit Dhillon: greater than 0,\n",
      "\n",
      "00:28:53.620 --> 00:28:02.840\n",
      "Inderjit Dhillon: summation\n",
      "\n",
      "256\n",
      "00:28:02.770 --> 00:28:04.direction\n",
      "\n",
      "258\n",
      "00:28:08.660 --> 00:28:14.450\n",
      "Euclide day Ds ip-official framework. Right? But through quite coun only n N. Times,000 Xran.\n",
      "\n",
      "\n",
      "346\n",
      "00:39:57.380 --> 00:44:06.880\n",
      "Inderjit Dhillon: Okay. And the other plus adding objective.\n",
      "\n",
      "41\n",
      "00:35:01.860 --> 00:35:03.730\n",
      "Inderjit Dhillon: maximum value.\n",
      "\n",
      "432\n",
      "00:35:03.089 --> 00:35:16.610\n",
      "Nilesh Gupta: the board way in code so, some support vector machines. And These are another, and maybe decide how, like they happens that on our neural network like right direction here\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "15\n",
      "00:03:39.700 --> 00:03:47.940\n",
      "Nilesh Gupta: this is the equation.\n",
      "\n",
      "15\n",
      "Inderjit Dhillon: ildam with respect and transformer algorithm\n",
      "\n",
      "157\n",
      "00:19:56.890 --> 00:19:57.020\n",
      "Inderjit Dhillon: so. You would look at the same cluster submission method \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = generate(net)\n",
    "print(decode(out[0].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to implementing the forward pass of the transformer, you will also need to tweak different hyperparameters of the model, such as the number of heads, the number of layers, the embedding dimension, and the block size. You will then need to report the training and validation loss with different hyperparameters. You can try 3 different values for each hyperparameter (one below the default value and one above) independently and report the results in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(param_name, samples, training_losses, validation_losses):\n",
    "    print (\"{:<20} {:<20} {:<20}\".format(param_name,'Training Loss','Validation Loss'))\n",
    "    for i in range(len(samples)):\n",
    "        print (\"{:<20} {:<20} {:<20}\".format(samples[i], training_losses[i], validation_losses[i]))\n",
    "\n",
    "heads = [2, 4, 8]\n",
    "layers = [2, 4, 8]\n",
    "emb_dims = [32, 64, 128]\n",
    "block_sizes = [16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.710: 100%|██████████| 3366/3366 [33:04<00:00,  1.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [01:13<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.755: 100%|██████████| 3366/3366 [33:38<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [01:14<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.758: 100%|██████████| 3366/3366 [39:16<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [01:41<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.151\n",
      "Number of Heads      Training Loss        Validation Loss     \n",
      "2                    1.7100489361967561   2.147502196462531   \n",
      "4                    1.7545494494945324   2.1188209467812587  \n",
      "8                    1.7579337354224847   2.150640647976022   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "for num_heads in heads:\n",
    "    net = Transformer(VOCAB_SIZE, EMB_DIM, HIDDEN_DIM, N_LAYERS, num_heads, DROPOUT)\n",
    "    optim = torch.optim.AdamW(net.parameters(), lr=LR, weight_decay=0.01)\n",
    "    training_losses.append(train(net, optim, trn_loader))\n",
    "    validation_losses.append(eval(net, val_loader))\n",
    "table(\"Number of Heads\", heads, training_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.834: 100%|██████████| 3366/3366 [09:23<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:22<00:00, 16.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.810: 100%|██████████| 3366/3366 [14:38<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:32<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.804: 100%|██████████| 3366/3366 [22:24<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:55<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.111\n",
      "Number of Layers     Training Loss        Validation Loss     \n",
      "2                    1.8342900619008182   2.090036714796632   \n",
      "4                    1.8100076372327367   2.101323988493972   \n",
      "8                    1.80411289804972     2.1107275304518973  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "for num_layers in layers:\n",
    "    net = Transformer(VOCAB_SIZE, EMB_DIM, HIDDEN_DIM, num_layers, NUM_HEADS, DROPOUT)\n",
    "    optim = torch.optim.AdamW(net.parameters(), lr=LR, weight_decay=0.01)\n",
    "    training_losses.append(train(net, optim, trn_loader))\n",
    "    validation_losses.append(eval(net, val_loader))\n",
    "table(\"Number of Layers\", layers, training_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 2.041: 100%|██████████| 3366/3366 [09:14<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:23<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.816: 100%|██████████| 3366/3366 [13:24<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:34<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.592: 100%|██████████| 3366/3366 [28:36<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [01:09<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.300\n",
      "Embedding Dimension  Training Loss        Validation Loss     \n",
      "32                   2.0414910014371253   2.096812045793208   \n",
      "64                   1.8156625077402881   2.098882383561823   \n",
      "128                  1.5918939977406181   2.3003213881194746  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "for emb_dim in emb_dims:\n",
    "    hidden_dim = 4 * emb_dim\n",
    "    net = Transformer(VOCAB_SIZE, emb_dim, hidden_dim, N_LAYERS, NUM_HEADS, DROPOUT)\n",
    "    optim = torch.optim.AdamW(net.parameters(), lr=LR, weight_decay=0.01)\n",
    "    training_losses.append(train(net, optim, trn_loader))\n",
    "    validation_losses.append(eval(net, val_loader))\n",
    "table(\"Embedding Dimension\", emb_dims, training_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.953: 100%|██████████| 3366/3366 [07:13<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:17<00:00, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.809: 100%|██████████| 3366/3366 [14:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:35<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1, Loss: 1.708: 100%|██████████| 3366/3366 [34:27<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [01:30<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.166\n",
      "Block Size           Training Loss        Validation Loss     \n",
      "16                   1.9534008368026339   2.1041596927667854  \n",
      "32                   1.8089005991028522   2.0936161282807197  \n",
      "64                   1.7075570740660102   2.166194853970879   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "for block_size in block_sizes:\n",
    "    BLOCK_SIZE = block_size\n",
    "    trn_dataset = Dataset(trn_data, BLOCK_SIZE)\n",
    "    val_dataset = Dataset(val_data, BLOCK_SIZE)\n",
    "    trn_loader = torch.utils.data.DataLoader(trn_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    net = Transformer(VOCAB_SIZE, EMB_DIM, HIDDEN_DIM, N_LAYERS, NUM_HEADS, DROPOUT)\n",
    "    optim = torch.optim.AdamW(net.parameters(), lr=LR, weight_decay=0.01)\n",
    "    training_losses.append(train(net, optim, trn_loader))\n",
    "    validation_losses.append(eval(net, val_loader))\n",
    "table(\"Block Size\", block_sizes, training_losses, validation_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
